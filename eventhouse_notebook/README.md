# ğŸ“Š Spark Application Insights Notebook

This PySpark notebook processes Spark event logs from Azure Data Explorer (Kusto), analyzes application behavior, and populates `eventHouseTelemetry` tables with summaries, performance metrics, predictions, and recommendations.

---

## ğŸ”§ Configuration

### 1. Kusto Cluster Settings

Update the following placeholders in the Notebook:

~~~ python
kustoUri = "<https://your-kusto-cluster.kusto.data.microsoft.com>"
~~~

## ğŸ“ˆ Output

The notebook generates and processes data into **5 outputs per application**:

- âœ… `metadata_df`: metadata of the run
- âœ… `summary_df`: Top 5 slowest Spark stages  
- ğŸ“Š `metrics_df`: Execution and performance metrics  
- ğŸ”® `predictions_df`: Estimated durations with varied executor counts  
- ğŸ’¡ `recommendations_df`: Actionable performance suggestions  

You can optionally write these to Kusto or other storage (see **[Optional: Output to Kusto]** section below).

---

## â° Scheduling

To run this notebook daily, configure it using pipeline. 
