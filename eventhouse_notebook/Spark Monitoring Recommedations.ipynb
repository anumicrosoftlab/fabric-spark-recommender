{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77988b79-a4b3-4da9-8c1e-c7dd72fc83b3",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# PySpark Application Runtime & Task Analysis\n",
    "\n",
    "Unlock the performance story behind your Spark applications.  \n",
    "\n",
    "This **PySpark-based script** dives into Spark event logs from eventhouse.\n",
    "\n",
    "## üîç What It Provides\n",
    "\n",
    "- ‚è± **Total Application Runtime**  \n",
    "  Measure how long your Spark application actually ran from start to finish.\n",
    "\n",
    "- üßÆ **Executor Wall-Clock Time (Non-Overlapping)**  \n",
    "  Compute accurate, non-overlapping time spent by all executors to assess real resource usage.\n",
    "\n",
    "- üñ•Ô∏è **Driver Wall Clock Time**  \n",
    "  Identify how much time was spent on the driver node ‚Äî a key indicator of centralized or unbalanced workloads.\n",
    "\n",
    "- üìä **Task-Level Summaries**  \n",
    "  Analyze task-level performance, including execution time, I/O metrics, shuffle details, and per-stage skew stats. \n",
    "\n",
    "- üìà **Runtime Scaling Predictions**  \n",
    "  Simulate how application runtime changes with more executors to estimate scalability and cost efficiency.\n",
    "\n",
    "- üí° **Actionable Recommendations**  \n",
    "  Get context-aware tips on improving performance, enabling native execution, and optimizing resource usage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b101ec61-8867-49d8-b793-08e5e06747f2",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-06-05T13:35:38.3930981Z",
       "execution_start_time": "2025-06-05T13:35:36.8148907Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "e6a45272-4b20-4344-9f56-acd660901f4a",
       "queued_time": "2025-06-05T13:35:36.8136594Z",
       "session_id": "f22d9d74-430c-4c22-8250-44c735a122a4",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 4,
       "statement_ids": [
        4
       ]
      },
      "text/plain": [
       "StatementMeta(, f22d9d74-430c-4c22-8250-44c735a122a4, 4, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql.functions import (\n",
    "    col, lit, count, countDistinct, avg, expr, percentile_approx,\n",
    "    min as spark_min, max as spark_max, sum as spark_sum, row_number\n",
    ")\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "from pyspark.sql import Row\n",
    "\n",
    "\n",
    "\n",
    "def compute_application_runtime(event_log_df):\n",
    "    start_row = event_log_df.filter(col(\"properties.Event\") == \"SparkListenerApplicationStart\") \\\n",
    "        .select((col(\"properties.Timestamp\") / 1000).cast(\"timestamp\").alias(\"start_time\")) \\\n",
    "        .limit(1).collect()\n",
    "\n",
    "    end_row = event_log_df.filter(col(\"properties.Event\") == \"SparkListenerApplicationEnd\") \\\n",
    "        .select((col(\"properties.Timestamp\") / 1000).cast(\"timestamp\").alias(\"end_time\")) \\\n",
    "        .limit(1).collect()\n",
    "\n",
    "    if start_row and end_row:\n",
    "        return (end_row[0][\"end_time\"].timestamp() - start_row[0][\"start_time\"].timestamp())\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def compute_executor_wall_clock_time(event_log_df):\n",
    "    task_end_df = event_log_df.filter(col(\"properties.Event\") == \"SparkListenerTaskEnd\") \\\n",
    "        .select(\n",
    "            col(\"properties.Task Info.Launch Time\").alias(\"start_time\"),\n",
    "            col(\"properties.Task Info.Finish Time\").alias(\"end_time\")\n",
    "        ).dropna()\n",
    "\n",
    "    intervals = task_end_df.selectExpr(\"start_time / 1000 as start_sec\", \"end_time / 1000 as end_sec\") \\\n",
    "        .orderBy(\"start_sec\")\n",
    "\n",
    "    merged_intervals = []\n",
    "    for row in intervals.collect():\n",
    "        start, end = row[\"start_sec\"], row[\"end_sec\"]\n",
    "        if not merged_intervals or merged_intervals[-1][1] < start:\n",
    "            merged_intervals.append([start, end])\n",
    "        else:\n",
    "            merged_intervals[-1][1] = max(merged_intervals[-1][1], end)\n",
    "\n",
    "    return sum(end - start for start, end in merged_intervals)\n",
    "\n",
    "\n",
    "def estimate_runtime_scaling(task_df, executor_wall_clock_sec, driver_wall_clock_sec, current_executors, critical_path_sec):\n",
    "    critical_path_ms = critical_path_sec * 1000\n",
    "    total_task_time_ms = task_df.agg(spark_sum(\"executor_run_time_ms\")).first()[0]\n",
    "    parallelizable_ms = total_task_time_ms - critical_path_ms\n",
    "\n",
    "    if not total_task_time_ms or not executor_wall_clock_sec:\n",
    "        return pd.DataFrame([])\n",
    "\n",
    "    total_wall_clock_sec = executor_wall_clock_sec + driver_wall_clock_sec\n",
    "    predictions = []\n",
    "\n",
    "    driver_ratio = driver_wall_clock_sec / total_wall_clock_sec\n",
    "\n",
    "    for multiplier in [1.0, 2.0, 3.0, 4.0, 5.0]:\n",
    "        new_executors = max(1, int(current_executors * multiplier))\n",
    "        \n",
    "        # Estimate executor time with critical path + parallel work\n",
    "        estimated_executor_sec = (critical_path_ms + (parallelizable_ms / new_executors)) / 1000.0\n",
    "\n",
    "        # Estimate overlap: higher driver_ratio means less parallelism\n",
    "        overlap_weight = 1 - driver_wall_clock_sec / (driver_wall_clock_sec + estimated_executor_sec)\n",
    "\n",
    "        # Weighted estimate: somewhere between max and sum\n",
    "        app_duration_sec = max(driver_wall_clock_sec, estimated_executor_sec) + overlap_weight * min(driver_wall_clock_sec, estimated_executor_sec)\n",
    "\n",
    "        # Adjust app duration with driver-executor mix\n",
    "        # app_duration_sec = driver_ratio * driver_wall_clock_sec + (1 - driver_ratio) * estimated_executor_sec + driver_wall_clock_sec\n",
    "\n",
    "\n",
    "        predictions.append({\n",
    "            \"Executor Count\": new_executors,\n",
    "            \"Executor Multiplier\": f\"{int(multiplier * 100)}%\",\n",
    "            \"Estimated Executor WallClock\": f\"{int(estimated_executor_sec // 60)}m {int(estimated_executor_sec % 60)}s\",\n",
    "            \"Estimated Total Duration\": f\"{int(app_duration_sec // 60)}m {int(app_duration_sec % 60)}s\",\n",
    "        })\n",
    "\n",
    "    # print(predictions)\n",
    "\n",
    "    schema = StructType([\n",
    "    StructField(\"app_id\", StringType(), False),\n",
    "    StructField(\"Executor_Count\", IntegerType(), False),\n",
    "    StructField(\"Executor_Multiplier\", DoubleType(), False),\n",
    "    StructField(\"Estimated_Executor_WallClock\", StringType(), False),\n",
    "    StructField(\"Estimated_Total_Duration\", StringType(), False),\n",
    "])\n",
    "\n",
    "    # print(\"predictions table\")\n",
    "\n",
    "    # df = spark.createDataFrame(predictions, schema=schema)\n",
    "\n",
    "    #     # --- Show the DataFrame ---\n",
    "    # df.show(truncate=False)\n",
    "\n",
    "    # display(pd.DataFrame(predictions))\n",
    "\n",
    "    return pd.DataFrame(predictions)\n",
    "\n",
    "\n",
    "\n",
    "def generate_recommendations(app_duration_sec, driver_wall_clock_sec, executor_wall_clock_sec, metadata_df, task_df):\n",
    "    recs = []\n",
    "\n",
    "    driver_pct = 100 * driver_wall_clock_sec / app_duration_sec\n",
    "    executor_pct = 100 * executor_wall_clock_sec / app_duration_sec\n",
    "\n",
    "    if driver_pct > 70:\n",
    "        recs.append(\"This Spark job is driver-heavy (driver time > 70%). Consider parallelizing more operations to offload work to executors.\")\n",
    "\n",
    "    if \"spark.native.enabled\" in metadata_df.columns:\n",
    "        nee_enabled = metadata_df.select(\"`spark.native.enabled`\").first()[0]\n",
    "        if nee_enabled in [False, \"false\"] and executor_pct > 50:\n",
    "            recs.append(\"Native Execution Engine (NEE) is disabled, but executors are doing significant work. Enable NEE for performance gains without added cost.\")\n",
    "\n",
    "    if driver_pct > 99:\n",
    "        recs.append(\"This appears to be Python-native code running entirely on the driver. Run on Fabric Python kernel or refactor into Spark code for better parallelism.\")\n",
    "\n",
    "    if \"spark.synapse.session.tag.HIGH_CONCURRENCY_SESSION_TAG\" in metadata_df.columns and \"artifactType\" in metadata_df.columns:\n",
    "        hc_enabled = metadata_df.select(\"spark.synapse.session.tag.HIGH_CONCURRENCY_SESSION_TAG\").first()[0]\n",
    "        artifact_type = metadata_df.select(\"artifactType\").first()[0] if driver_pct < 98 else None\n",
    "        if hc_enabled in [False, \"false\", None] and artifact_type == \"SynapseNotebook\":\n",
    "            recs.append(\"High Concurrency is disabled for Fabric Notebook. Consider enabling High Concurrency mode to pack more notebooks into fewer sessions and save costs.\")\n",
    "\n",
    "    rec_rows = [Row(app_id=app_id, recommendation=rec) for rec in recs]\n",
    "\n",
    "    # If no recommendations, return a default \"No issues found\"\n",
    "    if not rec_rows:\n",
    "        rec_rows = [Row(app_id=app_id, recommendation=\"No performance recommendations found.\")]\n",
    "\n",
    "    # Create DataFrame\n",
    "    rec_df = spark.createDataFrame(rec_rows)\n",
    "    # print(\"recommedations table\")\n",
    "    # rec_df.show(truncate=False)\n",
    "\n",
    "    return rec_df\n",
    "\n",
    "\n",
    "def compute_stage_task_summary(event_log_df, metadata_df, app_id):\n",
    "    task_end_df = event_log_df.filter(col(\"properties.Event\") == \"SparkListenerTaskEnd\").withColumn(\"applicationID\", lit(app_id))\n",
    "\n",
    "    tasks_df = task_end_df.select(\n",
    "        col(\"properties.Stage ID\").alias(\"stage_id\"),\n",
    "        col(\"properties.Stage Attempt ID\").alias(\"stage_attempt_id\"),\n",
    "        col(\"properties.Task Info.Task ID\").alias(\"task_id\"),\n",
    "        col(\"properties.Task Info.Executor ID\").alias(\"executor_id\"),\n",
    "        col(\"properties.Task Info.Launch Time\").alias(\"launch_time\"),\n",
    "        col(\"properties.Task Info.Finish Time\").alias(\"finish_time\"),\n",
    "        col(\"properties.Task Info.Failed\").alias(\"failed\"),\n",
    "        (col(\"properties.Task Metrics.Executor Run Time\") / 1000).alias(\"duration_sec\"),\n",
    "        (col(\"properties.Task Metrics.Input Metrics.Bytes Read\") / 1024 / 1024).alias(\"input_mb\"),\n",
    "        col(\"properties.Task Metrics.Input Metrics.Records Read\").alias(\"input_records\"),\n",
    "        (col(\"properties.Task Metrics.Shuffle Read Metrics.Remote Bytes Read\") / 1024 / 1024).alias(\"shuffle_read_mb\"),\n",
    "        col(\"properties.Task Metrics.Shuffle Read Metrics.Total Records Read\").alias(\"shuffle_read_records\"),\n",
    "        (col(\"properties.Task Metrics.Shuffle Write Metrics.Shuffle Bytes Written\") / 1024 / 1024).alias(\"shuffle_write_mb\"),\n",
    "        col(\"properties.Task Metrics.Shuffle Write Metrics.Shuffle Records Written\").alias(\"shuffle_write_records\"),\n",
    "        (col(\"properties.Task Metrics.Output Metrics.Bytes Written\") / 1024 / 1024).alias(\"output_mb\"),\n",
    "        col(\"properties.Task Metrics.Output Metrics.Records Written\").alias(\"output_records\")\n",
    "    ).filter(col(\"failed\") == False)\n",
    "\n",
    "    stage_duration_df = tasks_df.groupBy(\"stage_id\", \"stage_attempt_id\").agg(\n",
    "        spark_min(\"launch_time\").alias(\"min_launch_time\"),\n",
    "        spark_max(\"finish_time\").alias(\"max_finish_time\"),\n",
    "        countDistinct(\"executor_id\").alias(\"num_executors\")\n",
    "    ).withColumn(\n",
    "        \"stage_execution_time_sec\", expr(\"(max_finish_time - min_launch_time) / 1000\")\n",
    "    )\n",
    "\n",
    "    stage_summary_df = tasks_df.groupBy(\"stage_id\", \"stage_attempt_id\").agg(\n",
    "        count(\"task_id\").alias(\"num_tasks\"),\n",
    "        count(expr(\"CASE WHEN failed = false THEN 1 END\")).alias(\"successful_tasks\"),\n",
    "        count(expr(\"CASE WHEN failed = true THEN 1 END\")).alias(\"failed_tasks\"),\n",
    "\n",
    "        spark_min(\"duration_sec\").alias(\"min_duration_sec\"),\n",
    "        spark_max(\"duration_sec\").alias(\"max_duration_sec\"),\n",
    "        avg(\"duration_sec\").alias(\"avg_duration_sec\"),\n",
    "        percentile_approx(\"duration_sec\", 0.75).alias(\"p75_duration_sec\"),\n",
    "\n",
    "        avg(\"shuffle_read_mb\").alias(\"avg_shuffle_read_mb\"),\n",
    "        spark_max(\"shuffle_read_mb\").alias(\"max_shuffle_read_mb\"),\n",
    "        avg(\"shuffle_read_records\").alias(\"avg_shuffle_read_records\"),\n",
    "        spark_max(\"shuffle_read_records\").alias(\"max_shuffle_read_records\"),\n",
    "\n",
    "        avg(\"shuffle_write_mb\").alias(\"avg_shuffle_write_mb\"),\n",
    "        spark_max(\"shuffle_write_mb\").alias(\"max_shuffle_write_mb\"),\n",
    "        avg(\"shuffle_write_records\").alias(\"avg_shuffle_write_records\"),\n",
    "        spark_max(\"shuffle_write_records\").alias(\"max_shuffle_write_records\"),\n",
    "\n",
    "        avg(\"input_mb\").alias(\"avg_input_mb\"),\n",
    "        spark_max(\"input_mb\").alias(\"max_input_mb\"),\n",
    "        avg(\"input_records\").alias(\"avg_input_records\"),\n",
    "        spark_max(\"input_records\").alias(\"max_input_records\"),\n",
    "\n",
    "        avg(\"output_mb\").alias(\"avg_output_mb\"),\n",
    "        spark_max(\"output_mb\").alias(\"max_output_mb\"),\n",
    "        avg(\"output_records\").alias(\"avg_output_records\"),\n",
    "        spark_max(\"output_records\").alias(\"max_output_records\")\n",
    "    )\n",
    "\n",
    "    final_summary_df = stage_summary_df.join(\n",
    "        stage_duration_df, on=[\"stage_id\", \"stage_attempt_id\"], how=\"left\"\n",
    "    ).orderBy(col(\"stage_execution_time_sec\").desc()).limit(5)\n",
    "\n",
    "    app_duration_sec = compute_application_runtime(event_log_df)\n",
    "    executor_wall_clock_sec = compute_executor_wall_clock_time(event_log_df)\n",
    "    driver_wall_clock_sec = app_duration_sec - executor_wall_clock_sec\n",
    "    max_executors = tasks_df.select(\"executor_id\").distinct().count()\n",
    "\n",
    "    # print(f\"Application Duration: {app_duration_sec:.2f} sec\")\n",
    "    # print(f\"Executor Wall Clock Time (non-overlapping): {executor_wall_clock_sec:.2f} sec\")\n",
    "    # print(f\"Driver Wall Clock Time (estimated): {driver_wall_clock_sec:.2f} sec\")\n",
    "    # print(f\"Executor Time % of App Time: {100 * executor_wall_clock_sec / app_duration_sec:.2f}%\")\n",
    "    # print(f\"Driver Time % of App Time: {100 * driver_wall_clock_sec / app_duration_sec:.2f}%\")\n",
    "    # print(f\"Maximum Number of Executors Ran: {max_executors}\")\n",
    "\n",
    "    per_stage_max_df = tasks_df.groupBy(\"stage_id\").agg(spark_max(\"duration_sec\").alias(\"max_task_time_sec\"))\n",
    "    critical_path_row = per_stage_max_df.agg(spark_sum(\"max_task_time_sec\").alias(\"critical_path_time_sec\")).first()\n",
    "    critical_path_sec = critical_path_row[\"critical_path_time_sec\"]\n",
    "\n",
    "    task_df = tasks_df.withColumn(\"executor_run_time_ms\", col(\"duration_sec\") * 1000)\n",
    "\n",
    "    schema = StructType([\n",
    "    StructField(\"Executor Count\", IntegerType(), True),\n",
    "    StructField(\"Executor Multiplier\", StringType(), True),\n",
    "    StructField(\"Estimated Executor WallClock\", StringType(), True),\n",
    "    StructField(\"Estimated Total Duration\", StringType(), True)\n",
    "    ])\n",
    "\n",
    "    empty_df = spark.createDataFrame([], schema)\n",
    "\n",
    "    if critical_path_sec:\n",
    "        print(f\"Critical Path Time: {critical_path_sec:.2f} sec\")\n",
    "        predictions_df=estimate_runtime_scaling(task_df, executor_wall_clock_sec, driver_wall_clock_sec, max_executors, critical_path_sec)\n",
    "    else:\n",
    "        predictions_df=empty_df\n",
    "        print(\"Critical Path could not be computed.\")\n",
    "\n",
    "    \n",
    "\n",
    "    # Prepare metrics list\n",
    "    metrics = [\n",
    "        (\"Application Duration (sec)\", round(app_duration_sec, 2)),\n",
    "        (\"Executor Wall Clock Time (sec)\", round(executor_wall_clock_sec, 2)),\n",
    "        (\"Driver Wall Clock Time (sec)\", round(driver_wall_clock_sec, 2)),\n",
    "        (\"Executor Time % of App Time\", round(100 * executor_wall_clock_sec / app_duration_sec, 2)),\n",
    "        (\"Driver Time % of App Time\", round(100 * driver_wall_clock_sec / app_duration_sec, 2)),\n",
    "        (\"Max Executors\", max_executors),\n",
    "        (\"Critical Path Time (sec)\", round(critical_path_sec, 2))\n",
    "    ]\n",
    "\n",
    "    # Convert metrics to rows with app_id\n",
    "    metrics_rows = [Row(app_id=app_id, metric=key, value=float(value)) for key, value in metrics]\n",
    "\n",
    "    # Define schema explicitly for the metrics DataFrame\n",
    "    schema = StructType([\n",
    "        StructField(\"app_id\", StringType(), False),\n",
    "        StructField(\"metric\", StringType(), False),\n",
    "        StructField(\"value\", DoubleType(), False)\n",
    "    ])\n",
    "\n",
    "    # Create DataFrame\n",
    "    metrics_df = spark.createDataFrame(metrics_rows, schema=schema)\n",
    "\n",
    "    # # Show the DataFrame\n",
    "    # display(metrics_df)\n",
    "\n",
    "    recommendations_df=generate_recommendations(app_duration_sec, driver_wall_clock_sec, executor_wall_clock_sec, metadata_df, task_df)\n",
    "\n",
    "    return final_summary_df, metrics_df, predictions_df, recommendations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109c5863-1813-4302-a9c5-bd342fbc902b",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Eventhouse Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21ade11-5390-47ba-a428-0b4d39296125",
   "metadata": {
    "advisor": {
     "adviceMetadata": "{\"artifactId\":\"b248dfe8-d5dd-44ca-a2bc-c052093565d0\",\"activityId\":\"f22d9d74-430c-4c22-8250-44c735a122a4\",\"applicationId\":\"application_1749129914961_0001\",\"jobGroupId\":\"5\",\"advices\":{\"info\":46,\"warn\":2}}"
    },
    "collapsed": false,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-06-05T13:55:22.0479671Z",
       "execution_start_time": "2025-06-05T13:35:38.3952901Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "1b057bba-ee81-49f9-b1e5-7b6e77f45976",
       "queued_time": "2025-06-05T13:35:37.1504442Z",
       "session_id": "f22d9d74-430c-4c22-8250-44c735a122a4",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 5,
       "statement_ids": [
        5
       ]
      },
      "text/plain": [
       "StatementMeta(, f22d9d74-430c-4c22-8250-44c735a122a4, 5, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Found 244 applications.\n",
      "INFO:root:Processing application ID: application_1749114690277_0001, application number: 1\n",
      "INFO:root:Processing application ID: application_1749085893549_0001, application number: 2\n",
      "INFO:root:Processing application ID: application_1749089487591_0001, application number: 3\n",
      "INFO:root:Processing application ID: application_1749109305932_0001, application number: 4\n",
      "INFO:root:Processing application ID: application_1749111091244_0001, application number: 5\n",
      "INFO:root:Processing application ID: application_1749057091585_0001, application number: 6\n",
      "INFO:root:Processing application ID: application_1749087692578_0001, application number: 7\n",
      "INFO:root:Processing application ID: application_1749096693801_0001, application number: 8\n",
      "INFO:root:Processing application ID: application_1749091293622_0001, application number: 9\n",
      "INFO:root:Processing application ID: application_1749075110565_0001, application number: 10\n",
      "INFO:root:Processing application ID: application_1749053493065_0001, application number: 11\n",
      "INFO:root:Processing application ID: application_1749039094314_0001, application number: 12\n",
      "INFO:root:Processing application ID: application_1749058895069_0001, application number: 13\n",
      "INFO:root:Processing application ID: application_1749098505547_0001, application number: 14\n",
      "INFO:root:Processing application ID: application_1749105758428_0001, application number: 15\n",
      "INFO:root:Processing application ID: application_1749080490694_0001, application number: 16\n",
      "INFO:root:Processing application ID: application_1749064291863_0001, application number: 17\n",
      "INFO:root:Processing application ID: application_1749093087046_0001, application number: 18\n",
      "INFO:root:Processing application ID: application_1749062497537_0001, application number: 19\n",
      "INFO:root:Processing application ID: application_1749066085918_0001, application number: 20\n",
      "INFO:root:Processing application ID: application_1749051690423_0001, application number: 21\n",
      "INFO:root:Processing application ID: application_1749116490452_0001, application number: 22\n",
      "INFO:root:Processing application ID: application_1749069688189_0001, application number: 23\n",
      "INFO:root:Processing application ID: application_1749030094185_0001, application number: 24\n",
      "INFO:root:Processing application ID: application_1749082289760_0001, application number: 25\n",
      "INFO:root:Processing application ID: application_1749107503227_0001, application number: 26\n",
      "INFO:root:Processing application ID: application_1749078687508_0001, application number: 27\n",
      "INFO:root:Processing application ID: application_1749060692926_0001, application number: 28\n",
      "INFO:root:Processing application ID: application_1749067907408_0001, application number: 29\n",
      "INFO:root:Processing application ID: application_1749112887147_0001, application number: 30\n",
      "INFO:root:Processing application ID: application_1749037290400_0001, application number: 31\n",
      "INFO:root:Processing application ID: application_1749042692763_0001, application number: 32\n",
      "INFO:root:Processing application ID: application_1749055289436_0001, application number: 33\n",
      "INFO:root:Processing application ID: application_1749031902545_0001, application number: 34\n",
      "INFO:root:Processing application ID: application_1749049883977_0001, application number: 35\n",
      "INFO:root:Processing application ID: application_1749048095816_0001, application number: 36\n",
      "INFO:root:Processing application ID: application_1749084090048_0001, application number: 37\n",
      "INFO:root:Processing application ID: application_1749035491272_0001, application number: 38\n",
      "INFO:root:Processing application ID: application_1749044492695_0001, application number: 39\n",
      "INFO:root:Processing application ID: application_1749046287083_0001, application number: 40\n",
      "INFO:root:Processing application ID: application_1749040891157_0001, application number: 41\n",
      "INFO:root:Processing application ID: application_1749071491224_0001, application number: 42\n",
      "INFO:root:Processing application ID: application_1749033688988_0001, application number: 43\n",
      "INFO:root:Processing application ID: application_1749094885948_0001, application number: 44\n",
      "INFO:root:Processing application ID: application_1749102096148_0001, application number: 45\n",
      "INFO:root:Processing application ID: application_1749073295482_0001, application number: 46\n",
      "INFO:root:Processing application ID: application_1749076899926_0001, application number: 47\n",
      "INFO:root:Processing application ID: application_1749100288975_0001, application number: 48\n",
      "INFO:root:Processing application ID: application_1749103892028_0001, application number: 49\n",
      "INFO:root:Processing application ID: application_1748981489360_0001, application number: 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critical Path Time: 27.88 sec\n",
      "Critical Path Time: 29.64 sec\n",
      "Critical Path Time: 30.93 sec\n",
      "Critical Path Time: 30.93 sec\n",
      "Critical Path Time: 37.24 sec\n",
      "Critical Path Time: 29.58 sec\n",
      "Critical Path Time: 29.45 sec\n",
      "Critical Path Time: 32.06 sec\n",
      "Critical Path Time: 28.10 sec\n",
      "Critical Path Time: 28.56 sec\n",
      "Critical Path Time: 29.38 sec\n",
      "Critical Path Time: 29.33 sec\n",
      "Critical Path Time: 31.34 sec\n",
      "Critical Path Time: 30.23 sec\n",
      "Critical Path Time: 30.62 sec\n",
      "Critical Path Time: 26.44 sec\n",
      "Critical Path Time: 30.01 sec\n",
      "Critical Path Time: 31.13 sec\n",
      "Critical Path Time: 29.30 sec\n",
      "Critical Path Time: 29.09 sec\n",
      "Critical Path Time: 30.21 sec\n",
      "Critical Path Time: 27.30 sec\n",
      "Critical Path Time: 27.85 sec\n",
      "Critical Path Time: 29.30 sec\n",
      "Critical Path Time: 29.76 sec\n",
      "Critical Path Time: 30.38 sec\n",
      "Critical Path Time: 34.79 sec\n",
      "Critical Path Time: 27.98 sec\n",
      "Critical Path Time: 29.35 sec\n",
      "Critical Path Time: 27.82 sec\n",
      "Critical Path Time: 30.32 sec\n",
      "Critical Path Time: 28.81 sec\n",
      "Critical Path Time: 27.18 sec\n",
      "Critical Path Time: 27.81 sec\n",
      "Critical Path Time: 27.58 sec\n",
      "Critical Path Time: 55.52 sec\n",
      "Critical Path Time: 28.83 sec\n",
      "Critical Path Time: 28.54 sec\n",
      "Critical Path Time: 31.48 sec\n",
      "Critical Path Time: 30.51 sec\n",
      "Critical Path Time: 27.93 sec\n",
      "Critical Path Time: 27.59 sec\n",
      "Critical Path Time: 30.02 sec\n",
      "Critical Path Time: 28.50 sec\n",
      "Critical Path Time: 32.06 sec\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.functions import col, from_json, lit, length\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# === Configuration ===\n",
    "# kustoQuery = \"['ingestionTable']\"\n",
    "kustoQuery = \"\"\"\n",
    "ingestionTable\n",
    "| where applicationId !in (sparklens_metadata | project applicationId)\n",
    "\"\"\"\n",
    "# The query URI for reading the data e.g. https://<>.kusto.data.microsoft.com.\n",
    "kustoUri = <https://<>.kusto.data.microsoft.com>\n",
    "# The database with data to be read.\n",
    "database = \"eventHouseTelemetry\"\n",
    "# The access credentials.\n",
    "accessToken = mssparkutils.credentials.getToken(kustoUri)\n",
    "kustoDf  = spark.read\\\n",
    "    .format(\"com.microsoft.kusto.spark.synapse.datasource\")\\\n",
    "    .option(\"accessToken\", accessToken)\\\n",
    "    .option(\"kustoCluster\", kustoUri)\\\n",
    "    .option(\"kustoDatabase\", database)\\\n",
    "    .option(\"kustoQuery\", kustoQuery).load()\n",
    "\n",
    "# # Show all distinct categories first\n",
    "# kustoDf.select(\"category\").distinct().show()\n",
    "\n",
    "# Filter the Kusto DataFrame for rows where category is \"EventLog\"\n",
    "filtered_df = kustoDf.filter(col(\"category\") == \"EventLog\")\n",
    "\n",
    "# Optionally show a few rows to verify\n",
    "filtered_df.count()\n",
    "\n",
    "# === 2.1 Infer Schema from Properties ===\n",
    "json_rdd = (\n",
    "    filtered_df\n",
    "    .filter(col(\"properties\").isNotNull())\n",
    "    .selectExpr(\"CAST(properties AS STRING) as json_str\")\n",
    "    .rdd\n",
    "    .map(lambda row: row[\"json_str\"])\n",
    ")\n",
    "\n",
    "sample_df = spark.read.json(json_rdd)\n",
    "\n",
    "# sample_df.show()\n",
    "\n",
    "sample_schema = sample_df.schema\n",
    "\n",
    "event_log_df = filtered_df.withColumn(\"properties\", from_json(col(\"properties\"), sample_schema))\n",
    "\n",
    "# === 3. Extract Metadata ===\n",
    "def extract_app_metadata(df):\n",
    "    native_enabled_df = df.selectExpr(\"properties.`Spark Properties`.`spark.native.enabled` AS spark_native_enabled\") \\\n",
    "                          .filter(col(\"spark_native_enabled\").isNotNull()) \\\n",
    "                          .distinct() \\\n",
    "                          .limit(1)\n",
    "\n",
    "    native_enabled = native_enabled_df.collect()[0][\"spark_native_enabled\"] if not native_enabled_df.rdd.isEmpty() else None\n",
    "\n",
    "    return df.select(\n",
    "        \"applicationId\", \"applicationName\", \"artifactId\", \"artifactType\", \"capacityId\",\n",
    "        \"executorMax\", \"executorMin\", \"fabricEnvId\", \"fabricLivyId\", \"fabricTenantId\",\n",
    "        \"fabricWorkspaceId\", \"isHighConcurrencyEnabled\"\n",
    "    ).distinct().withColumn(\"spark.native.enabled\", lit(native_enabled))\n",
    "\n",
    "metadata_df = extract_app_metadata(event_log_df)\n",
    "# metadata_df.show(truncate=False)\n",
    "\n",
    "# === 4. Process Each Application ID ===\n",
    "app_ids = metadata_df.select(\"applicationId\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "logging.info(f\"Found {len(app_ids)} applications.\")\n",
    "\n",
    "summary_dfs = []\n",
    "metrics_df = []\n",
    "predictions_df =[]\n",
    "recommendations_df = []\n",
    "\n",
    "# # app_ids=[\"application_1747957044383_0001\"]\n",
    "\n",
    "i=0\n",
    "\n",
    "for app_id in app_ids:\n",
    "    i += 1\n",
    "    logging.info(f\"Processing application ID: {app_id}, application number: {i}\")\n",
    "\n",
    "    filtered_event_log_df = event_log_df.filter(col(\"applicationId\") == app_id)\n",
    "    filtered_metadata_df = metadata_df.filter(col(\"applicationId\") == app_id)\n",
    "\n",
    "    start_events = filtered_event_log_df \\\n",
    "        .filter(col(\"properties.Event\") == \"SparkListenerApplicationStart\") \\\n",
    "        .select(\"properties.Timestamp\") \\\n",
    "        .limit(1) \\\n",
    "        .collect()\n",
    "\n",
    "    if not start_events:\n",
    "        logging.warning(f\"Missing SparkListenerApplicationStart event for {app_id}\")\n",
    "        error_row = Row(applicationID=app_id, error=\"Missing SparkListenerApplicationStart event\")\n",
    "        summary_dfs.append(spark.createDataFrame([error_row]))\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        app_summary_df_list = compute_stage_task_summary(filtered_event_log_df, filtered_metadata_df, app_id)\n",
    "        # app_summary_df = app_summary_df_list[0]\n",
    "        metrics_df.append(app_summary_df_list[1])\n",
    "        predictions_df.append(app_summary_df_list[2])\n",
    "        recommendations_df.append(app_summary_df_list[3])\n",
    "        summary_dfs.append(app_summary_df_list[0])\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing application {app_id}: {str(e)}\")\n",
    "        error_row = Row(applicationID=app_id, error=str(e))\n",
    "        summary_dfs.append(spark.createDataFrame([error_row]))\n",
    "\n",
    "from pyspark.sql import DataFrame as SparkDataFrame\n",
    "\n",
    "# Combine all DataFrames in summary_dfs list\n",
    "summary_df = None\n",
    "if summary_dfs:\n",
    "    summary_df = summary_dfs[0]\n",
    "    for sdf in summary_dfs[1:]:\n",
    "        summary_df = summary_df.unionByName(sdf, allowMissingColumns=True)\n",
    "\n",
    "# Convert metrics_df items if needed\n",
    "for i, df in enumerate(metrics_df):\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        metrics_df[i] = spark.createDataFrame(df)\n",
    "    elif not isinstance(df, SparkDataFrame):\n",
    "        raise TypeError(f\"metrics_df[{i}] is not a valid DataFrame.\")\n",
    "\n",
    "metrics_df_combined = metrics_df[0]\n",
    "for df in metrics_df[1:]:\n",
    "    metrics_df_combined = metrics_df_combined.unionByName(df, allowMissingColumns=True)\n",
    "\n",
    "# Convert predictions_df items if needed\n",
    "for i, df in enumerate(predictions_df):\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        predictions_df[i] = spark.createDataFrame(df)\n",
    "    elif not isinstance(df, SparkDataFrame):\n",
    "        raise TypeError(f\"predictions_df[{i}] is not a valid DataFrame.\")\n",
    "\n",
    "predictions_df_combined = predictions_df[0]\n",
    "for df in predictions_df[1:]:\n",
    "    predictions_df_combined = predictions_df_combined.unionByName(df, allowMissingColumns=True)\n",
    "\n",
    "# Convert recommendations_df items if needed\n",
    "for i, df in enumerate(recommendations_df):\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        recommendations_df[i] = spark.createDataFrame(df)\n",
    "    elif not isinstance(df, SparkDataFrame):\n",
    "        raise TypeError(f\"recommendations_df[{i}] is not a valid DataFrame.\")\n",
    "\n",
    "recommendations_df_combined = recommendations_df[0]\n",
    "for df in recommendations_df[1:]:\n",
    "    recommendations_df_combined = recommendations_df_combined.unionByName(df, allowMissingColumns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13e70047-5fd3-42ef-841d-546036f5ef2c",
   "metadata": {
    "collapsed": false,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-06-05T14:03:23.5341503Z",
       "execution_start_time": "2025-06-05T13:55:22.0506392Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "3f3a98ce-061c-4a61-b8cd-39ed58903d01",
       "queued_time": "2025-06-05T13:35:37.9107141Z",
       "session_id": "f22d9d74-430c-4c22-8250-44c735a122a4",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 6,
       "statement_ids": [
        6
       ]
      },
      "text/plain": [
       "StatementMeta(, f22d9d74-430c-4c22-8250-44c735a122a4, 6, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing results to EventHouse\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"writing results to EventHouse\")\n",
    "metadata_df.write \\\n",
    "    .format(\"com.microsoft.kusto.spark.synapse.datasource\") \\\n",
    "    .option(\"accessToken\", accessToken) \\\n",
    "    .option(\"kustoCluster\", kustoUri)\\\n",
    "    .option(\"kustoDatabase\", database)\\\n",
    "    .option(\"kustoTable\", \"sparklens_metadata\") \\\n",
    "    .option(\"tableCreateOptions\", \"CreateIfNotExist\") \\\n",
    "    .mode(\"Append\") \\\n",
    "    .save()\n",
    "\n",
    "summary_df.write \\\n",
    "    .format(\"com.microsoft.kusto.spark.synapse.datasource\") \\\n",
    "    .option(\"accessToken\", accessToken) \\\n",
    "    .option(\"kustoCluster\", kustoUri)\\\n",
    "    .option(\"kustoDatabase\", database)\\\n",
    "    .option(\"kustoTable\", \"sparklens_summary\") \\\n",
    "    .option(\"tableCreateOptions\", \"CreateIfNotExist\") \\\n",
    "    .mode(\"Append\") \\\n",
    "    .save()\n",
    "\n",
    "metrics_df_combined.write \\\n",
    "    .format(\"com.microsoft.kusto.spark.synapse.datasource\") \\\n",
    "    .option(\"accessToken\", accessToken) \\\n",
    "    .option(\"kustoCluster\", kustoUri)\\\n",
    "    .option(\"kustoDatabase\", database)\\\n",
    "    .option(\"kustoTable\", \"sparklens_metrics\") \\\n",
    "    .option(\"tableCreateOptions\", \"CreateIfNotExist\") \\\n",
    "    .mode(\"Append\") \\\n",
    "    .save()\n",
    "\n",
    "predictions_df_combined.write \\\n",
    "    .format(\"com.microsoft.kusto.spark.synapse.datasource\") \\\n",
    "    .option(\"accessToken\", accessToken) \\\n",
    "    .option(\"kustoCluster\", kustoUri)\\\n",
    "    .option(\"kustoDatabase\", database)\\\n",
    "    .option(\"kustoTable\", \"sparklens_predictions\") \\\n",
    "    .option(\"tableCreateOptions\", \"CreateIfNotExist\") \\\n",
    "    .mode(\"Append\") \\\n",
    "    .save()\n",
    "\n",
    "recommendations_df_combined.write \\\n",
    "    .format(\"com.microsoft.kusto.spark.synapse.datasource\") \\\n",
    "    .option(\"accessToken\", accessToken) \\\n",
    "    .option(\"kustoCluster\", kustoUri)\\\n",
    "    .option(\"kustoDatabase\", database)\\\n",
    "    .option(\"kustoTable\", \"sparklens_recommedations\") \\\n",
    "    .option(\"tableCreateOptions\", \"CreateIfNotExist\") \\\n",
    "    .mode(\"Append\") \\\n",
    "    .save()"
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "environment": {},
   "lakehouse": {
    "default_lakehouse": "0cab43c5-72e8-46ce-83f2-d05b37448b41",
    "default_lakehouse_name": "sparklens_api",
    "default_lakehouse_workspace_id": "d36ffa51-fc09-46c8-aa6d-563b6cc9eb70",
    "known_lakehouses": [
     {
      "id": "0cab43c5-72e8-46ce-83f2-d05b37448b41"
     }
    ]
   }
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  },
  "synapse_widget": {
   "state": {},
   "version": "0.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
